{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD5kbXszcbqjwgJ5hKlHb5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjini-rao/Neural-Network_PharmaProbe/blob/main/Clean_Neural_Net_No_PCA_for_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4VyNnOMB6NR1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "a4671364-c890-4b16-d89c-fa4f3fb0b46d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   uniqueID                 drugName                     condition  \\\n",
              "0     95260               Guanfacine                          ADHD   \n",
              "1     92703                   Lybrel                 Birth Control   \n",
              "2    138000               Ortho Evra                 Birth Control   \n",
              "3     35696  Buprenorphine  naloxone             Opiate Dependence   \n",
              "4    155963                   Cialis  Benign Prostatic Hyperplasia   \n",
              "\n",
              "                                              review  rating       date  \\\n",
              "0  My son is halfway through his fourth week of I...     8.0  27-Apr-10   \n",
              "1  I used to take another oral contraceptive whic...     5.0  14-Dec-09   \n",
              "2  This is my first time using any form of birth ...     8.0   3-Nov-15   \n",
              "3  Suboxone has completely turned my life around ...     9.0  27-Nov-16   \n",
              "4  2nd day on 5mg started to work with rock hard ...     2.0  28-Nov-15   \n",
              "\n",
              "   usefulCount  lengthReview  conditionCluster_label  drugNameCluster_label  \\\n",
              "0        192.0         712.0                     2.0                    4.0   \n",
              "1         17.0         708.0                     9.0                    6.0   \n",
              "2         10.0         428.0                     9.0                    4.0   \n",
              "3         37.0         669.0                     0.0                    2.0   \n",
              "4         43.0         373.0                     0.0                    5.0   \n",
              "\n",
              "   ...       758       759       760       761       762       763       764  \\\n",
              "0  ... -0.416409 -0.364040 -0.036060  0.383963  0.176255 -0.147201 -0.243359   \n",
              "1  ... -0.279307 -0.419729 -0.389261  0.328398  0.291834 -0.027217 -0.359790   \n",
              "2  ... -0.232733 -0.031823 -0.032784  0.188440  0.162272  0.363399 -0.096650   \n",
              "3  ... -0.310564 -0.599643 -0.375174  0.309915  0.577983  0.051811 -0.184821   \n",
              "4  ... -0.247983 -0.438636 -0.037911 -0.030183  0.508780  0.064493 -0.205261   \n",
              "\n",
              "        765       766       767  \n",
              "0 -0.541467  0.062160  0.049585  \n",
              "1 -0.706709  0.047264 -0.017902  \n",
              "2 -0.693634 -0.024901  0.548486  \n",
              "3 -0.710691  0.065533  0.371945  \n",
              "4 -0.527391 -0.101341  0.039573  \n",
              "\n",
              "[5 rows x 778 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a5b1b44-efc3-493c-b600-4b355b0ea0d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniqueID</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>lengthReview</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>drugNameCluster_label</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95260</td>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>My son is halfway through his fourth week of I...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>27-Apr-10</td>\n",
              "      <td>192.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.416409</td>\n",
              "      <td>-0.364040</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.383963</td>\n",
              "      <td>0.176255</td>\n",
              "      <td>-0.147201</td>\n",
              "      <td>-0.243359</td>\n",
              "      <td>-0.541467</td>\n",
              "      <td>0.062160</td>\n",
              "      <td>0.049585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92703</td>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>I used to take another oral contraceptive whic...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14-Dec-09</td>\n",
              "      <td>17.0</td>\n",
              "      <td>708.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.279307</td>\n",
              "      <td>-0.419729</td>\n",
              "      <td>-0.389261</td>\n",
              "      <td>0.328398</td>\n",
              "      <td>0.291834</td>\n",
              "      <td>-0.027217</td>\n",
              "      <td>-0.359790</td>\n",
              "      <td>-0.706709</td>\n",
              "      <td>0.047264</td>\n",
              "      <td>-0.017902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>138000</td>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>This is my first time using any form of birth ...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3-Nov-15</td>\n",
              "      <td>10.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232733</td>\n",
              "      <td>-0.031823</td>\n",
              "      <td>-0.032784</td>\n",
              "      <td>0.188440</td>\n",
              "      <td>0.162272</td>\n",
              "      <td>0.363399</td>\n",
              "      <td>-0.096650</td>\n",
              "      <td>-0.693634</td>\n",
              "      <td>-0.024901</td>\n",
              "      <td>0.548486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35696</td>\n",
              "      <td>Buprenorphine  naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>Suboxone has completely turned my life around ...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>27-Nov-16</td>\n",
              "      <td>37.0</td>\n",
              "      <td>669.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>-0.599643</td>\n",
              "      <td>-0.375174</td>\n",
              "      <td>0.309915</td>\n",
              "      <td>0.577983</td>\n",
              "      <td>0.051811</td>\n",
              "      <td>-0.184821</td>\n",
              "      <td>-0.710691</td>\n",
              "      <td>0.065533</td>\n",
              "      <td>0.371945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155963</td>\n",
              "      <td>Cialis</td>\n",
              "      <td>Benign Prostatic Hyperplasia</td>\n",
              "      <td>2nd day on 5mg started to work with rock hard ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28-Nov-15</td>\n",
              "      <td>43.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.247983</td>\n",
              "      <td>-0.438636</td>\n",
              "      <td>-0.037911</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>0.508780</td>\n",
              "      <td>0.064493</td>\n",
              "      <td>-0.205261</td>\n",
              "      <td>-0.527391</td>\n",
              "      <td>-0.101341</td>\n",
              "      <td>0.039573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 778 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a5b1b44-efc3-493c-b600-4b355b0ea0d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a5b1b44-efc3-493c-b600-4b355b0ea0d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a5b1b44-efc3-493c-b600-4b355b0ea0d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8aa8f4cd-ec9d-4c0c-8d64-1c97a067d02a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8aa8f4cd-ec9d-4c0c-8d64-1c97a067d02a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8aa8f4cd-ec9d-4c0c-8d64-1c97a067d02a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "embedded_df = pd.read_csv('embedded_review.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify it was loaded correctly\n",
        "embedded_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedded_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daKqS3a96i-l",
        "outputId": "de5c4e27-4050-4a3b-886b-60376dea718c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11316"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This Neural Net is just going to focus on classifying the Condition Cluster by the Review Embeddings\n",
        "#This Neural Net is also going to use the dataframe that has not had dimensions reduced\n",
        "\n",
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xr4mDZzP6nvX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am going to drop the columns that are not embeddings of the review and the condition_cluster\n",
        "\n",
        "columns_to_drop = ['uniqueID', 'drugName', 'date', 'condition', 'review', 'lengthReview']\n",
        "\n",
        "embedded_df.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "ytUNWz5_6pvE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the dataframe\n",
        "\n",
        "embedded_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "VGRdZ9WN6sC6",
        "outputId": "3ea31771-2731-4e50-981b-9a6b0052cb58"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  usefulCount  conditionCluster_label  drugNameCluster_label  \\\n",
              "0     8.0        192.0                     2.0                    4.0   \n",
              "1     5.0         17.0                     9.0                    6.0   \n",
              "2     8.0         10.0                     9.0                    4.0   \n",
              "3     9.0         37.0                     0.0                    2.0   \n",
              "4     2.0         43.0                     0.0                    5.0   \n",
              "\n",
              "          0         1         2         3         4         5  ...       758  \\\n",
              "0 -0.010977  0.010914  0.200967 -0.229490 -0.535286  0.012419  ... -0.416409   \n",
              "1  0.066320  0.189584  0.369006 -0.046920 -0.473988 -0.238288  ... -0.279307   \n",
              "2  0.084101 -0.019134  0.294494  0.029783 -0.228783  0.170102  ... -0.232733   \n",
              "3  0.007820  0.207558  0.179105 -0.210057 -0.197015  0.104799  ... -0.310564   \n",
              "4 -0.193177  0.360585  0.448292 -0.253824 -0.532782  0.085381  ... -0.247983   \n",
              "\n",
              "        759       760       761       762       763       764       765  \\\n",
              "0 -0.364040 -0.036060  0.383963  0.176255 -0.147201 -0.243359 -0.541467   \n",
              "1 -0.419729 -0.389261  0.328398  0.291834 -0.027217 -0.359790 -0.706709   \n",
              "2 -0.031823 -0.032784  0.188440  0.162272  0.363399 -0.096650 -0.693634   \n",
              "3 -0.599643 -0.375174  0.309915  0.577983  0.051811 -0.184821 -0.710691   \n",
              "4 -0.438636 -0.037911 -0.030183  0.508780  0.064493 -0.205261 -0.527391   \n",
              "\n",
              "        766       767  \n",
              "0  0.062160  0.049585  \n",
              "1  0.047264 -0.017902  \n",
              "2 -0.024901  0.548486  \n",
              "3  0.065533  0.371945  \n",
              "4 -0.101341  0.039573  \n",
              "\n",
              "[5 rows x 772 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16cefb30-45f9-4000-8d40-250d8a166029\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>drugNameCluster_label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.010977</td>\n",
              "      <td>0.010914</td>\n",
              "      <td>0.200967</td>\n",
              "      <td>-0.229490</td>\n",
              "      <td>-0.535286</td>\n",
              "      <td>0.012419</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.416409</td>\n",
              "      <td>-0.364040</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.383963</td>\n",
              "      <td>0.176255</td>\n",
              "      <td>-0.147201</td>\n",
              "      <td>-0.243359</td>\n",
              "      <td>-0.541467</td>\n",
              "      <td>0.062160</td>\n",
              "      <td>0.049585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.066320</td>\n",
              "      <td>0.189584</td>\n",
              "      <td>0.369006</td>\n",
              "      <td>-0.046920</td>\n",
              "      <td>-0.473988</td>\n",
              "      <td>-0.238288</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.279307</td>\n",
              "      <td>-0.419729</td>\n",
              "      <td>-0.389261</td>\n",
              "      <td>0.328398</td>\n",
              "      <td>0.291834</td>\n",
              "      <td>-0.027217</td>\n",
              "      <td>-0.359790</td>\n",
              "      <td>-0.706709</td>\n",
              "      <td>0.047264</td>\n",
              "      <td>-0.017902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.084101</td>\n",
              "      <td>-0.019134</td>\n",
              "      <td>0.294494</td>\n",
              "      <td>0.029783</td>\n",
              "      <td>-0.228783</td>\n",
              "      <td>0.170102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232733</td>\n",
              "      <td>-0.031823</td>\n",
              "      <td>-0.032784</td>\n",
              "      <td>0.188440</td>\n",
              "      <td>0.162272</td>\n",
              "      <td>0.363399</td>\n",
              "      <td>-0.096650</td>\n",
              "      <td>-0.693634</td>\n",
              "      <td>-0.024901</td>\n",
              "      <td>0.548486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.207558</td>\n",
              "      <td>0.179105</td>\n",
              "      <td>-0.210057</td>\n",
              "      <td>-0.197015</td>\n",
              "      <td>0.104799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>-0.599643</td>\n",
              "      <td>-0.375174</td>\n",
              "      <td>0.309915</td>\n",
              "      <td>0.577983</td>\n",
              "      <td>0.051811</td>\n",
              "      <td>-0.184821</td>\n",
              "      <td>-0.710691</td>\n",
              "      <td>0.065533</td>\n",
              "      <td>0.371945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.193177</td>\n",
              "      <td>0.360585</td>\n",
              "      <td>0.448292</td>\n",
              "      <td>-0.253824</td>\n",
              "      <td>-0.532782</td>\n",
              "      <td>0.085381</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.247983</td>\n",
              "      <td>-0.438636</td>\n",
              "      <td>-0.037911</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>0.508780</td>\n",
              "      <td>0.064493</td>\n",
              "      <td>-0.205261</td>\n",
              "      <td>-0.527391</td>\n",
              "      <td>-0.101341</td>\n",
              "      <td>0.039573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 772 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16cefb30-45f9-4000-8d40-250d8a166029')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16cefb30-45f9-4000-8d40-250d8a166029 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16cefb30-45f9-4000-8d40-250d8a166029');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d055fe8-2f66-41b5-a385-1b4055301d1a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d055fe8-2f66-41b5-a385-1b4055301d1a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d055fe8-2f66-41b5-a385-1b4055301d1a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking on why the values of the condition cluster look like a float\n",
        "\n",
        "condition_value_counts = embedded_df['conditionCluster_label'].value_counts()\n",
        "print(condition_value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jMeoThU65Q_",
        "outputId": "33506be1-53bb-4119-9579-284fcc394ba8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    4074\n",
            "8.0    2100\n",
            "2.0     955\n",
            "1.0     865\n",
            "7.0     777\n",
            "9.0     752\n",
            "4.0     736\n",
            "5.0     356\n",
            "3.0     353\n",
            "6.0     347\n",
            "Name: conditionCluster_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When I start training the model I am getting an error messsage that NAN values are present\n",
        "embedded_df = embedded_df.dropna(subset=['conditionCluster_label'])"
      ],
      "metadata": {
        "id": "9IfvnqVh67HQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "# Choosing randon_state = 30 to be able to re-create attempts later\n",
        "# There is a lot of data, so I can train on 70%, setting test_size at .3\n",
        "# This step is necessary for training the neural network to classify 10 categories\n",
        "# This code is altered by chatgpt after I could not fix it on my own\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Separate the target variable\n",
        "target = embedded_df['conditionCluster_label']\n",
        "\n",
        "# Verify the unique values in the target variable\n",
        "print(target.unique())\n",
        "\n",
        "# Extract features (excluding the target variable)\n",
        "features = embedded_df.drop(columns=['conditionCluster_label'])\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=30)\n",
        "\n",
        "# Convert target labels to one-hot encoded format\n",
        "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Check the shapes of the one-hot encoded target labels\n",
        "print(\"Shape of y_train_encoded:\", y_train_encoded.shape)\n",
        "print(\"Shape of y_test_encoded:\", y_test_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCCETtsI69C7",
        "outputId": "a0e5a54a-874b-4bb8-ca85-9686ada66c84"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 9. 0. 1. 3. 8. 5. 7. 4. 6.]\n",
            "Shape of y_train_encoded: (7920, 10)\n",
            "Shape of y_test_encoded: (3395, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "O23diebR6__s"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dimensions, make it a variable so it passes into\n",
        "\n",
        "num_dimensions = embedded_df.shape[1]-1\n",
        "print(num_dimensions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYq1MvQx7CIg",
        "outputId": "cedc22a4-d5c2-4bf7-bed5-eef3821e1b34"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "# Most of this is going to be the same as the HW assignment, but there are 10 classifications to predict now\n",
        "# So the output layer has been adjusted\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=771, activation=\"sigmoid\", input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(Dense(units=600, activation='sigmoid'))\n",
        "\n",
        "# Third hidden layer (example of adding an additional hidden layer)\n",
        "nn.add(Dense(units=300, activation='sigmoid'))\n",
        "\n",
        "#Fourth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=150, activation='ELU'))\n",
        "\n",
        "#Fifth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=100, activation='leaky_relu'))\n",
        "\n",
        "#Sixth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=50, activation='relu'))\n",
        "\n",
        "#Seventh hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=25, activation='ELU'))\n",
        "\n",
        "#Eighth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=15, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=10, activation='softmax'))  # 10 units for 10 classes, softmax activation\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le9upw8D7tdf",
        "outputId": "f7c97af7-78f6-413d-c4da-af4394e5079d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 771)               595212    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 600)               463200    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 300)               180300    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 150)               45150     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 100)               15100     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 15)                390       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1305837 (4.98 MB)\n",
            "Trainable params: 1305837 (4.98 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model - the loss function is categorical and not for binary classification\n",
        "\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "k-g2YqfH7vx_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=10)"
      ],
      "metadata": {
        "id": "RCMHwJZ-70Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfd2bb2-7092-4ce3-a5ca-a0d261210c4c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "248/248 [==============================] - 7s 21ms/step - loss: 1.8436 - accuracy: 0.3574\n",
            "Epoch 2/10\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5876 - accuracy: 0.3961\n",
            "Epoch 3/10\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 1.4617 - accuracy: 0.4486\n",
            "Epoch 4/10\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 1.3650 - accuracy: 0.4855\n",
            "Epoch 5/10\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.2721 - accuracy: 0.5119\n",
            "Epoch 6/10\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.1960 - accuracy: 0.5370\n",
            "Epoch 7/10\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.1095 - accuracy: 0.5672\n",
            "Epoch 8/10\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.0306 - accuracy: 0.6010\n",
            "Epoch 9/10\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.9238 - accuracy: 0.6428\n",
            "Epoch 10/10\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.8201 - accuracy: 0.6875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9hNCz472VB",
        "outputId": "21b93bf3-b0b1-4fc5-9c71-15c580a8277e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7478 - accuracy: 0.4489\n",
            "Test Loss: 1.7478067874908447\n",
            "Test Accuracy: 0.4488954246044159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the test results from the above Neural Net\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Get predicted probabilities for each class\n",
        "y_pred_probabilities = nn.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to predicted classes by selecting the class with the highest probability\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test_encoded back to categorical labels\n",
        "y_test_categorical = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Create a DataFrame to compare predicted and actual classes\n",
        "result_df = pd.DataFrame({'Actual': y_test_categorical, 'Predicted': y_pred})\n",
        "\n",
        "# Add a column indicating whether the prediction was correct\n",
        "result_df['Correct'] = result_df['Actual'] == result_df['Predicted']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n",
        "\n",
        "# Calculate accuracy manually\n",
        "accuracy = result_df['Correct'].mean()\n",
        "print(\"Manual Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqZXmcYObLf",
        "outputId": "f984657b-853f-4768-a61c-1187bbb0f231"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 12ms/step\n",
            "      Actual  Predicted  Correct\n",
            "0          9          9     True\n",
            "1          0          4    False\n",
            "2          0          8    False\n",
            "3          8          0    False\n",
            "4          8          7    False\n",
            "...      ...        ...      ...\n",
            "3390       9          9     True\n",
            "3391       4          1    False\n",
            "3392       4          0    False\n",
            "3393       0          0     True\n",
            "3394       1          0    False\n",
            "\n",
            "[3395 rows x 3 columns]\n",
            "Manual Test Accuracy: 0.4488954344624448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Export result_df to a CSV file\n",
        "result_df.to_csv('prediction_results.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('prediction_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f7f5E3-aObq6",
        "outputId": "943c39cc-3000-4c10-c6cf-8c2c829452ab"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0ed35bab-e1f2-4005-acac-8b1973a85263\", \"prediction_results.csv\", 32451)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusting the learning rate\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Define the model - deep neural net with L2 regularization\n",
        "nn = Sequential()\n",
        "\n",
        "# First hidden layer with L2 regularization\n",
        "nn.add(Dense(units=771, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer with L2 regularization\n",
        "nn.add(Dense(units=512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Third hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Fourth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Fifth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Sixth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Seventh hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Eighth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Define optimizer with custom learning rate\n",
        "custom_optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compile the model with the custom optimizer\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=custom_optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3WMJtya77HB",
        "outputId": "3378f049-27c2-4a52-92a8-7e92b82717ef"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "248/248 [==============================] - 9s 29ms/step - loss: 5.4045 - accuracy: 0.3569\n",
            "Epoch 2/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 2.0712 - accuracy: 0.3600\n",
            "Epoch 3/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 2.0065 - accuracy: 0.3614\n",
            "Epoch 4/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.9707 - accuracy: 0.3640\n",
            "Epoch 5/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.9298 - accuracy: 0.3727\n",
            "Epoch 6/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.8996 - accuracy: 0.3732\n",
            "Epoch 7/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.8787 - accuracy: 0.3706\n",
            "Epoch 8/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.8573 - accuracy: 0.3708\n",
            "Epoch 9/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.8436 - accuracy: 0.3756\n",
            "Epoch 10/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.8397 - accuracy: 0.3775\n",
            "Epoch 11/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.8197 - accuracy: 0.3869\n",
            "Epoch 12/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.8177 - accuracy: 0.3939\n",
            "Epoch 13/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.8076 - accuracy: 0.3963\n",
            "Epoch 14/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 1.8069 - accuracy: 0.3981\n",
            "Epoch 15/200\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 1.7962 - accuracy: 0.4029\n",
            "Epoch 16/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.7867 - accuracy: 0.4056\n",
            "Epoch 17/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.7876 - accuracy: 0.4087\n",
            "Epoch 18/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.7869 - accuracy: 0.4072\n",
            "Epoch 19/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.7748 - accuracy: 0.4179\n",
            "Epoch 20/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.7708 - accuracy: 0.4164\n",
            "Epoch 21/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.7669 - accuracy: 0.4188\n",
            "Epoch 22/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.7607 - accuracy: 0.4247\n",
            "Epoch 23/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.7544 - accuracy: 0.4313\n",
            "Epoch 24/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.7561 - accuracy: 0.4251\n",
            "Epoch 25/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.7520 - accuracy: 0.4293\n",
            "Epoch 26/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.7459 - accuracy: 0.4336\n",
            "Epoch 27/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.7429 - accuracy: 0.4398\n",
            "Epoch 28/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.7330 - accuracy: 0.4385\n",
            "Epoch 29/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.7355 - accuracy: 0.4396\n",
            "Epoch 30/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.7256 - accuracy: 0.4423\n",
            "Epoch 31/200\n",
            "248/248 [==============================] - 8s 30ms/step - loss: 1.7174 - accuracy: 0.4460\n",
            "Epoch 32/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.7188 - accuracy: 0.4456\n",
            "Epoch 33/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.7202 - accuracy: 0.4473\n",
            "Epoch 34/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.7114 - accuracy: 0.4556\n",
            "Epoch 35/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.7088 - accuracy: 0.4492\n",
            "Epoch 36/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.6949 - accuracy: 0.4569\n",
            "Epoch 37/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.6971 - accuracy: 0.4525\n",
            "Epoch 38/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.6966 - accuracy: 0.4563\n",
            "Epoch 39/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.6923 - accuracy: 0.4591\n",
            "Epoch 40/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.6915 - accuracy: 0.4586\n",
            "Epoch 41/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.6805 - accuracy: 0.4617\n",
            "Epoch 42/200\n",
            "248/248 [==============================] - 8s 30ms/step - loss: 1.6782 - accuracy: 0.4630\n",
            "Epoch 43/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.6772 - accuracy: 0.4609\n",
            "Epoch 44/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6817 - accuracy: 0.4643\n",
            "Epoch 45/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.6708 - accuracy: 0.4629\n",
            "Epoch 46/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6715 - accuracy: 0.4629\n",
            "Epoch 47/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.6770 - accuracy: 0.4610\n",
            "Epoch 48/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.6571 - accuracy: 0.4722\n",
            "Epoch 49/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.6579 - accuracy: 0.4702\n",
            "Epoch 50/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.6623 - accuracy: 0.4707\n",
            "Epoch 51/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.6579 - accuracy: 0.4650\n",
            "Epoch 52/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.6413 - accuracy: 0.4765\n",
            "Epoch 53/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.6474 - accuracy: 0.4761\n",
            "Epoch 54/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.6557 - accuracy: 0.4662\n",
            "Epoch 55/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.6528 - accuracy: 0.4692\n",
            "Epoch 56/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 1.6491 - accuracy: 0.4797\n",
            "Epoch 57/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6392 - accuracy: 0.4813\n",
            "Epoch 58/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.6371 - accuracy: 0.4826\n",
            "Epoch 59/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.6357 - accuracy: 0.4819\n",
            "Epoch 60/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6423 - accuracy: 0.4802\n",
            "Epoch 61/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.6249 - accuracy: 0.4880\n",
            "Epoch 62/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6299 - accuracy: 0.4835\n",
            "Epoch 63/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.6281 - accuracy: 0.4859\n",
            "Epoch 64/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.6378 - accuracy: 0.4817\n",
            "Epoch 65/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.6350 - accuracy: 0.4879\n",
            "Epoch 66/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.6225 - accuracy: 0.4904\n",
            "Epoch 67/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.6178 - accuracy: 0.4912\n",
            "Epoch 68/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.6141 - accuracy: 0.4967\n",
            "Epoch 69/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.6293 - accuracy: 0.4933\n",
            "Epoch 70/200\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 1.6172 - accuracy: 0.4934\n",
            "Epoch 71/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.6242 - accuracy: 0.4949\n",
            "Epoch 72/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.6131 - accuracy: 0.4919\n",
            "Epoch 73/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.6209 - accuracy: 0.4949\n",
            "Epoch 74/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.6186 - accuracy: 0.4997\n",
            "Epoch 75/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.6099 - accuracy: 0.5019\n",
            "Epoch 76/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.6150 - accuracy: 0.4944\n",
            "Epoch 77/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6144 - accuracy: 0.5021\n",
            "Epoch 78/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.6086 - accuracy: 0.4986\n",
            "Epoch 79/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.6017 - accuracy: 0.4971\n",
            "Epoch 80/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5964 - accuracy: 0.5019\n",
            "Epoch 81/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.6185 - accuracy: 0.4996\n",
            "Epoch 82/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 1.6069 - accuracy: 0.5018\n",
            "Epoch 83/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.6007 - accuracy: 0.5006\n",
            "Epoch 84/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5951 - accuracy: 0.5016\n",
            "Epoch 85/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.6063 - accuracy: 0.4990\n",
            "Epoch 86/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.6081 - accuracy: 0.5003\n",
            "Epoch 87/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.5999 - accuracy: 0.5030\n",
            "Epoch 88/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.6057 - accuracy: 0.5040\n",
            "Epoch 89/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.6064 - accuracy: 0.4990\n",
            "Epoch 90/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.6019 - accuracy: 0.5049\n",
            "Epoch 91/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.5928 - accuracy: 0.5157\n",
            "Epoch 92/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5980 - accuracy: 0.5047\n",
            "Epoch 93/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5908 - accuracy: 0.5092\n",
            "Epoch 94/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5990 - accuracy: 0.5109\n",
            "Epoch 95/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5975 - accuracy: 0.5052\n",
            "Epoch 96/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.6018 - accuracy: 0.5114\n",
            "Epoch 97/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.6046 - accuracy: 0.5069\n",
            "Epoch 98/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5853 - accuracy: 0.5143\n",
            "Epoch 99/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5906 - accuracy: 0.5157\n",
            "Epoch 100/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5858 - accuracy: 0.5158\n",
            "Epoch 101/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.5843 - accuracy: 0.5191\n",
            "Epoch 102/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5820 - accuracy: 0.5184\n",
            "Epoch 103/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.5914 - accuracy: 0.5110\n",
            "Epoch 104/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5827 - accuracy: 0.5188\n",
            "Epoch 105/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.5861 - accuracy: 0.5176\n",
            "Epoch 106/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5925 - accuracy: 0.5170\n",
            "Epoch 107/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5871 - accuracy: 0.5172\n",
            "Epoch 108/200\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 1.5791 - accuracy: 0.5163\n",
            "Epoch 109/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5774 - accuracy: 0.5148\n",
            "Epoch 110/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5787 - accuracy: 0.5155\n",
            "Epoch 111/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 1.5786 - accuracy: 0.5263\n",
            "Epoch 112/200\n",
            "248/248 [==============================] - 8s 30ms/step - loss: 1.5821 - accuracy: 0.5181\n",
            "Epoch 113/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5753 - accuracy: 0.5245\n",
            "Epoch 114/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5744 - accuracy: 0.5285\n",
            "Epoch 115/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5793 - accuracy: 0.5216\n",
            "Epoch 116/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5769 - accuracy: 0.5227\n",
            "Epoch 117/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5927 - accuracy: 0.5205\n",
            "Epoch 118/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5739 - accuracy: 0.5222\n",
            "Epoch 119/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5680 - accuracy: 0.5280\n",
            "Epoch 120/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5919 - accuracy: 0.5181\n",
            "Epoch 121/200\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 1.5769 - accuracy: 0.5279\n",
            "Epoch 122/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 1.5606 - accuracy: 0.5319\n",
            "Epoch 123/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.5776 - accuracy: 0.5269\n",
            "Epoch 124/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5819 - accuracy: 0.5280\n",
            "Epoch 125/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.5663 - accuracy: 0.5287\n",
            "Epoch 126/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5571 - accuracy: 0.5314\n",
            "Epoch 127/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.5675 - accuracy: 0.5278\n",
            "Epoch 128/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.5759 - accuracy: 0.5282\n",
            "Epoch 129/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5699 - accuracy: 0.5283\n",
            "Epoch 130/200\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 1.5676 - accuracy: 0.5302\n",
            "Epoch 131/200\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 1.5548 - accuracy: 0.5307\n",
            "Epoch 132/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5915 - accuracy: 0.5260\n",
            "Epoch 133/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.5493 - accuracy: 0.5360\n",
            "Epoch 134/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5695 - accuracy: 0.5294\n",
            "Epoch 135/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.5602 - accuracy: 0.5280\n",
            "Epoch 136/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.5585 - accuracy: 0.5405\n",
            "Epoch 137/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5714 - accuracy: 0.5335\n",
            "Epoch 138/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.5606 - accuracy: 0.5423\n",
            "Epoch 139/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5668 - accuracy: 0.5313\n",
            "Epoch 140/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5828 - accuracy: 0.5303\n",
            "Epoch 141/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.5517 - accuracy: 0.5410\n",
            "Epoch 142/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.5543 - accuracy: 0.5428\n",
            "Epoch 143/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5695 - accuracy: 0.5314\n",
            "Epoch 144/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5524 - accuracy: 0.5415\n",
            "Epoch 145/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5422 - accuracy: 0.5457\n",
            "Epoch 146/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.5600 - accuracy: 0.5366\n",
            "Epoch 147/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 1.5696 - accuracy: 0.5354\n",
            "Epoch 148/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5494 - accuracy: 0.5399\n",
            "Epoch 149/200\n",
            "248/248 [==============================] - 8s 30ms/step - loss: 1.5576 - accuracy: 0.5374\n",
            "Epoch 150/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5546 - accuracy: 0.5324\n",
            "Epoch 151/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5467 - accuracy: 0.5383\n",
            "Epoch 152/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5516 - accuracy: 0.5433\n",
            "Epoch 153/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5409 - accuracy: 0.5443\n",
            "Epoch 154/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.5501 - accuracy: 0.5408\n",
            "Epoch 155/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5479 - accuracy: 0.5417\n",
            "Epoch 156/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5527 - accuracy: 0.5412\n",
            "Epoch 157/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5419 - accuracy: 0.5404\n",
            "Epoch 158/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5559 - accuracy: 0.5415\n",
            "Epoch 159/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5524 - accuracy: 0.5407\n",
            "Epoch 160/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5630 - accuracy: 0.5369\n",
            "Epoch 161/200\n",
            "248/248 [==============================] - 8s 32ms/step - loss: 1.5662 - accuracy: 0.5407\n",
            "Epoch 162/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.5422 - accuracy: 0.5446\n",
            "Epoch 163/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5705 - accuracy: 0.5354\n",
            "Epoch 164/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.5382 - accuracy: 0.5484\n",
            "Epoch 165/200\n",
            "248/248 [==============================] - 7s 30ms/step - loss: 1.5524 - accuracy: 0.5431\n",
            "Epoch 166/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5678 - accuracy: 0.5383\n",
            "Epoch 167/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.5430 - accuracy: 0.5481\n",
            "Epoch 168/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5411 - accuracy: 0.5422\n",
            "Epoch 169/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5412 - accuracy: 0.5447\n",
            "Epoch 170/200\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 1.5422 - accuracy: 0.5503\n",
            "Epoch 171/200\n",
            "248/248 [==============================] - 7s 28ms/step - loss: 1.5582 - accuracy: 0.5442\n",
            "Epoch 172/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5490 - accuracy: 0.5457\n",
            "Epoch 173/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5416 - accuracy: 0.5441\n",
            "Epoch 174/200\n",
            "248/248 [==============================] - 8s 30ms/step - loss: 1.5502 - accuracy: 0.5501\n",
            "Epoch 175/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5397 - accuracy: 0.5465\n",
            "Epoch 176/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5322 - accuracy: 0.5468\n",
            "Epoch 177/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5506 - accuracy: 0.5432\n",
            "Epoch 178/200\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 1.5459 - accuracy: 0.5463\n",
            "Epoch 179/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.5458 - accuracy: 0.5542\n",
            "Epoch 180/200\n",
            "248/248 [==============================] - 8s 31ms/step - loss: 1.5609 - accuracy: 0.5348\n",
            "Epoch 181/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5488 - accuracy: 0.5495\n",
            "Epoch 182/200\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 1.5328 - accuracy: 0.5521\n",
            "Epoch 183/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5465 - accuracy: 0.5504\n",
            "Epoch 184/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5408 - accuracy: 0.5495\n",
            "Epoch 185/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5439 - accuracy: 0.5501\n",
            "Epoch 186/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5462 - accuracy: 0.5496\n",
            "Epoch 187/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5554 - accuracy: 0.5434\n",
            "Epoch 188/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.5326 - accuracy: 0.5561\n",
            "Epoch 189/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5381 - accuracy: 0.5510\n",
            "Epoch 190/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.5560 - accuracy: 0.5490\n",
            "Epoch 191/200\n",
            "248/248 [==============================] - 6s 26ms/step - loss: 1.5161 - accuracy: 0.5587\n",
            "Epoch 192/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5395 - accuracy: 0.5506\n",
            "Epoch 193/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5421 - accuracy: 0.5489\n",
            "Epoch 194/200\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 1.5243 - accuracy: 0.5580\n",
            "Epoch 195/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.5616 - accuracy: 0.5414\n",
            "Epoch 196/200\n",
            "248/248 [==============================] - 7s 27ms/step - loss: 1.5459 - accuracy: 0.5506\n",
            "Epoch 197/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5219 - accuracy: 0.5551\n",
            "Epoch 198/200\n",
            "248/248 [==============================] - 7s 29ms/step - loss: 1.5329 - accuracy: 0.5554\n",
            "Epoch 199/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.5423 - accuracy: 0.5533\n",
            "Epoch 200/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.5456 - accuracy: 0.5451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxgKzktR7_vg",
        "outputId": "814d1594-e976-4635-8957-057ff7b30306"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 6ms/step - loss: 2.4738 - accuracy: 0.3770\n",
            "Test Loss: 2.4738454818725586\n",
            "Test Accuracy: 0.3770250380039215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the test results from the above Neural Net\n",
        "\n",
        "# Get predicted probabilities for each class\n",
        "y_pred_probabilities = nn.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to predicted classes by selecting the class with the highest probability\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test_encoded back to categorical labels\n",
        "y_test_categorical = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Create a DataFrame to compare predicted and actual classes\n",
        "result_df = pd.DataFrame({'Actual': y_test_categorical, 'Predicted': y_pred})\n",
        "\n",
        "# Add a column indicating whether the prediction was correct\n",
        "result_df['Correct'] = result_df['Actual'] == result_df['Predicted']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n",
        "\n",
        "# Calculate accuracy manually\n",
        "accuracy = result_df['Correct'].mean()\n",
        "print(\"Manual Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7cBhCkdVOOJ",
        "outputId": "7509675b-f638-4039-9778-a56750503280"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 11ms/step\n",
            "      Actual  Predicted  Correct\n",
            "0          9          0    False\n",
            "1          0          1    False\n",
            "2          0          0     True\n",
            "3          8          0    False\n",
            "4          8          7    False\n",
            "...      ...        ...      ...\n",
            "3390       9          7    False\n",
            "3391       4          1    False\n",
            "3392       4          0    False\n",
            "3393       0          0     True\n",
            "3394       1          0    False\n",
            "\n",
            "[3395 rows x 3 columns]\n",
            "Manual Test Accuracy: 0.37702503681885124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Export result_df to a CSV file\n",
        "result_df.to_csv('prediction_results.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('prediction_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YRVEawAVVOR0",
        "outputId": "e7b2d71f-98b9-40ba-9916-728a24a95606"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e6d941c-d3db-4653-aa67-d32fae3de3c4\", \"prediction_results.csv\", 32695)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QTBXeckYw8P",
        "outputId": "8a1be24d-cf63-4aa8-c94d-90435c82edf4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# Define the model-building function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(units=hp.Int('units_input', min_value=64, max_value=800, step=64), activation='relu', input_dim=num_dimensions))\n",
        "    for i in range(hp.Int('num_layers', 1, 8)):  # Number of hidden layers\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=64, max_value=512, step=64), activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Instantiate the tuner and perform hyperparameter search\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='helloworld')\n",
        "\n",
        "tuner.search(X_train_scaled, y_train_encoded, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Optimal number of units in the input layer: {best_hps.get('units_input')}\")\n",
        "print(f\"Optimal learning rate for the optimizer: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Optimal number of hidden layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Optimal number of units in layer {i}: {best_hps.get('units_' + str(i))}\")\n",
        "\n",
        "# Build the model with the best hyperparameters and train it on the data\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_scaled, y_train_encoded, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "5khmBoX0t30I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f728ca-91d0-4bd3-ee8a-4cc7e1f77ca7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 01m 33s]\n",
            "val_accuracy: 0.47453702489535016\n",
            "\n",
            "Best val_accuracy So Far: 0.6660353541374207\n",
            "Total elapsed time: 01h 06m 37s\n",
            "Optimal number of units in the input layer: 192\n",
            "Optimal learning rate for the optimizer: 0.0001\n",
            "Optimal number of hidden layers: 5\n",
            "Optimal number of units in layer 0: 256\n",
            "Optimal number of units in layer 1: 64\n",
            "Optimal number of units in layer 2: 64\n",
            "Optimal number of units in layer 3: 64\n",
            "Optimal number of units in layer 4: 64\n",
            "Epoch 1/50\n",
            "198/198 [==============================] - 4s 8ms/step - loss: 2.0044 - accuracy: 0.3382 - val_loss: 1.8381 - val_accuracy: 0.3763\n",
            "Epoch 2/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 1.7532 - accuracy: 0.3742 - val_loss: 1.6833 - val_accuracy: 0.3908\n",
            "Epoch 3/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 1.5417 - accuracy: 0.4433 - val_loss: 1.5671 - val_accuracy: 0.4198\n",
            "Epoch 4/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 1.3627 - accuracy: 0.5073 - val_loss: 1.5067 - val_accuracy: 0.4476\n",
            "Epoch 5/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 1.2234 - accuracy: 0.5579 - val_loss: 1.4973 - val_accuracy: 0.4602\n",
            "Epoch 6/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 1.0987 - accuracy: 0.6061 - val_loss: 1.5058 - val_accuracy: 0.4501\n",
            "Epoch 7/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.9809 - accuracy: 0.6548 - val_loss: 1.5391 - val_accuracy: 0.4508\n",
            "Epoch 8/50\n",
            "198/198 [==============================] - 2s 9ms/step - loss: 0.8716 - accuracy: 0.6965 - val_loss: 1.5423 - val_accuracy: 0.4602\n",
            "Epoch 9/50\n",
            "198/198 [==============================] - 2s 10ms/step - loss: 0.7626 - accuracy: 0.7525 - val_loss: 1.5963 - val_accuracy: 0.4665\n",
            "Epoch 10/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.6596 - accuracy: 0.7863 - val_loss: 1.6738 - val_accuracy: 0.4564\n",
            "Epoch 11/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.8294 - val_loss: 1.7567 - val_accuracy: 0.4615\n",
            "Epoch 12/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.8674 - val_loss: 1.8598 - val_accuracy: 0.4583\n",
            "Epoch 13/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8995 - val_loss: 1.9737 - val_accuracy: 0.4602\n",
            "Epoch 14/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.2976 - accuracy: 0.9296 - val_loss: 2.1357 - val_accuracy: 0.4438\n",
            "Epoch 15/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.2373 - accuracy: 0.9470 - val_loss: 2.2807 - val_accuracy: 0.4501\n",
            "Epoch 16/50\n",
            "198/198 [==============================] - 1s 5ms/step - loss: 0.1844 - accuracy: 0.9626 - val_loss: 2.4328 - val_accuracy: 0.4362\n",
            "Epoch 17/50\n",
            "198/198 [==============================] - 1s 5ms/step - loss: 0.1422 - accuracy: 0.9795 - val_loss: 2.6228 - val_accuracy: 0.4432\n",
            "Epoch 18/50\n",
            "198/198 [==============================] - 2s 8ms/step - loss: 0.1112 - accuracy: 0.9844 - val_loss: 2.7727 - val_accuracy: 0.4482\n",
            "Epoch 19/50\n",
            "198/198 [==============================] - 2s 12ms/step - loss: 0.0842 - accuracy: 0.9910 - val_loss: 2.9378 - val_accuracy: 0.4482\n",
            "Epoch 20/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0632 - accuracy: 0.9937 - val_loss: 3.0993 - val_accuracy: 0.4495\n",
            "Epoch 21/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.0481 - accuracy: 0.9968 - val_loss: 3.2590 - val_accuracy: 0.4438\n",
            "Epoch 22/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0348 - accuracy: 0.9984 - val_loss: 3.4129 - val_accuracy: 0.4451\n",
            "Epoch 23/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9989 - val_loss: 3.5474 - val_accuracy: 0.4356\n",
            "Epoch 24/50\n",
            "198/198 [==============================] - 1s 5ms/step - loss: 0.0211 - accuracy: 0.9991 - val_loss: 3.6957 - val_accuracy: 0.4356\n",
            "Epoch 25/50\n",
            "198/198 [==============================] - 1s 5ms/step - loss: 0.0170 - accuracy: 0.9989 - val_loss: 3.8335 - val_accuracy: 0.4350\n",
            "Epoch 26/50\n",
            "198/198 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.9989 - val_loss: 4.0203 - val_accuracy: 0.4646\n",
            "Epoch 27/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.2011 - accuracy: 0.9441 - val_loss: 3.4993 - val_accuracy: 0.4432\n",
            "Epoch 28/50\n",
            "198/198 [==============================] - 2s 8ms/step - loss: 0.0431 - accuracy: 0.9921 - val_loss: 3.6805 - val_accuracy: 0.4527\n",
            "Epoch 29/50\n",
            "198/198 [==============================] - 3s 13ms/step - loss: 0.0160 - accuracy: 0.9995 - val_loss: 3.7574 - val_accuracy: 0.4426\n",
            "Epoch 30/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.8390 - val_accuracy: 0.4489\n",
            "Epoch 31/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.9387 - val_accuracy: 0.4514\n",
            "Epoch 32/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.0282 - val_accuracy: 0.4520\n",
            "Epoch 33/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.1053 - val_accuracy: 0.4545\n",
            "Epoch 34/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.1797 - val_accuracy: 0.4482\n",
            "Epoch 35/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.2595 - val_accuracy: 0.4463\n",
            "Epoch 36/50\n",
            "198/198 [==============================] - 2s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.3276 - val_accuracy: 0.4482\n",
            "Epoch 37/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.4106 - val_accuracy: 0.4470\n",
            "Epoch 38/50\n",
            "198/198 [==============================] - 3s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.4773 - val_accuracy: 0.4470\n",
            "Epoch 39/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.5508 - val_accuracy: 0.4444\n",
            "Epoch 40/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.6166 - val_accuracy: 0.4432\n",
            "Epoch 41/50\n",
            "198/198 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.6823 - val_accuracy: 0.4419\n",
            "Epoch 42/50\n",
            "198/198 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.7537 - val_accuracy: 0.4413\n",
            "Epoch 43/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.8221 - val_accuracy: 0.4413\n",
            "Epoch 44/50\n",
            "198/198 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.8866 - val_accuracy: 0.4419\n",
            "Epoch 45/50\n",
            "198/198 [==============================] - 2s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.9605 - val_accuracy: 0.4432\n",
            "Epoch 46/50\n",
            "198/198 [==============================] - 2s 10ms/step - loss: 8.8178e-04 - accuracy: 1.0000 - val_loss: 5.0204 - val_accuracy: 0.4419\n",
            "Epoch 47/50\n",
            "198/198 [==============================] - 2s 11ms/step - loss: 7.7549e-04 - accuracy: 1.0000 - val_loss: 5.0904 - val_accuracy: 0.4438\n",
            "Epoch 48/50\n",
            "198/198 [==============================] - 1s 6ms/step - loss: 6.8675e-04 - accuracy: 1.0000 - val_loss: 5.1582 - val_accuracy: 0.4438\n",
            "Epoch 49/50\n",
            "198/198 [==============================] - 2s 8ms/step - loss: 6.0443e-04 - accuracy: 1.0000 - val_loss: 5.2189 - val_accuracy: 0.4451\n",
            "Epoch 50/50\n",
            "198/198 [==============================] - 1s 5ms/step - loss: 5.3207e-04 - accuracy: 1.0000 - val_loss: 5.2861 - val_accuracy: 0.4407\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 5.5640 - accuracy: 0.4330\n",
            "Test accuracy: 0.4329896867275238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Define the model - deep neural net with L2 regularization and custom learning rate\n",
        "nn = Sequential()\n",
        "\n",
        "# First hidden layer with L2 regularization\n",
        "nn.add(Dense(units=192, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Third hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Fourth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Fifth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Sixth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Seventh hidden layer with L2 regularization\n",
        "nn.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Define optimizer with custom learning rate\n",
        "custom_optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model with the custom optimizer\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=custom_optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZsYOzEgcFa9",
        "outputId": "71af7be0-8ab8-4fd8-cf1a-b383ae1731e5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "248/248 [==============================] - 4s 8ms/step - loss: 8.8904 - accuracy: 0.3299\n",
            "Epoch 2/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 6.6617 - accuracy: 0.3717\n",
            "Epoch 3/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 5.1718 - accuracy: 0.4207\n",
            "Epoch 4/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 4.2070 - accuracy: 0.4604\n",
            "Epoch 5/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 3.5699 - accuracy: 0.4847\n",
            "Epoch 6/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 3.1328 - accuracy: 0.5008\n",
            "Epoch 7/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 2.8216 - accuracy: 0.5210\n",
            "Epoch 8/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 2.5881 - accuracy: 0.5461\n",
            "Epoch 9/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 2.4105 - accuracy: 0.5590\n",
            "Epoch 10/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 2.2689 - accuracy: 0.5803\n",
            "Epoch 11/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 2.1474 - accuracy: 0.6053\n",
            "Epoch 12/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 2.0415 - accuracy: 0.6357\n",
            "Epoch 13/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 1.9458 - accuracy: 0.6650\n",
            "Epoch 14/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 1.8536 - accuracy: 0.6949\n",
            "Epoch 15/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 1.7644 - accuracy: 0.7316\n",
            "Epoch 16/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 1.6814 - accuracy: 0.7593\n",
            "Epoch 17/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 1.6101 - accuracy: 0.7866\n",
            "Epoch 18/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 1.5294 - accuracy: 0.8152\n",
            "Epoch 19/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 1.4614 - accuracy: 0.8398\n",
            "Epoch 20/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 1.4029 - accuracy: 0.8605\n",
            "Epoch 21/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 1.3352 - accuracy: 0.8896\n",
            "Epoch 22/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 1.2770 - accuracy: 0.9093\n",
            "Epoch 23/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 1.2439 - accuracy: 0.9178\n",
            "Epoch 24/200\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 1.1930 - accuracy: 0.9351\n",
            "Epoch 25/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 1.1517 - accuracy: 0.9489\n",
            "Epoch 26/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 1.1212 - accuracy: 0.9577\n",
            "Epoch 27/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 1.0784 - accuracy: 0.9691\n",
            "Epoch 28/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 1.0513 - accuracy: 0.9773\n",
            "Epoch 29/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 1.0322 - accuracy: 0.9771\n",
            "Epoch 30/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 1.0246 - accuracy: 0.9718\n",
            "Epoch 31/200\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 0.9835 - accuracy: 0.9860\n",
            "Epoch 32/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.9531 - accuracy: 0.9926\n",
            "Epoch 33/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.9369 - accuracy: 0.9894\n",
            "Epoch 34/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.9460 - accuracy: 0.9794\n",
            "Epoch 35/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.9229 - accuracy: 0.9855\n",
            "Epoch 36/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.8961 - accuracy: 0.9902\n",
            "Epoch 37/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.8960 - accuracy: 0.9824\n",
            "Epoch 38/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.9282 - accuracy: 0.9654\n",
            "Epoch 39/200\n",
            "248/248 [==============================] - 3s 10ms/step - loss: 0.8613 - accuracy: 0.9904\n",
            "Epoch 40/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.8149 - accuracy: 0.9989\n",
            "Epoch 41/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.7953 - accuracy: 0.9990\n",
            "Epoch 42/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.7788 - accuracy: 0.9996\n",
            "Epoch 43/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.7697 - accuracy: 0.9991\n",
            "Epoch 44/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.7837 - accuracy: 0.9919\n",
            "Epoch 45/200\n",
            "248/248 [==============================] - 3s 12ms/step - loss: 1.0129 - accuracy: 0.8934\n",
            "Epoch 46/200\n",
            "248/248 [==============================] - 3s 10ms/step - loss: 0.8045 - accuracy: 0.9843\n",
            "Epoch 47/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.7461 - accuracy: 0.9981\n",
            "Epoch 48/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.7239 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.7109 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.7015 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.6957 - accuracy: 0.9992\n",
            "Epoch 52/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.6926 - accuracy: 0.9997\n",
            "Epoch 53/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.7799 - accuracy: 0.9607\n",
            "Epoch 54/200\n",
            "248/248 [==============================] - 3s 10ms/step - loss: 0.9101 - accuracy: 0.9068\n",
            "Epoch 55/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.7087 - accuracy: 0.9936\n",
            "Epoch 56/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6704 - accuracy: 0.9997\n",
            "Epoch 57/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6567 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.6477 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.6418 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6345 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6306 - accuracy: 0.9999\n",
            "Epoch 62/200\n",
            "248/248 [==============================] - 2s 10ms/step - loss: 0.8421 - accuracy: 0.9220\n",
            "Epoch 63/200\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 0.7927 - accuracy: 0.9408\n",
            "Epoch 64/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6504 - accuracy: 0.9977\n",
            "Epoch 65/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.6230 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.6110 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.6038 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "248/248 [==============================] - 2s 10ms/step - loss: 0.5945 - accuracy: 0.9999\n",
            "Epoch 70/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.5947 - accuracy: 0.9994\n",
            "Epoch 71/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.8475 - accuracy: 0.9029\n",
            "Epoch 72/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.6968 - accuracy: 0.9669\n",
            "Epoch 73/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6127 - accuracy: 0.9979\n",
            "Epoch 74/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5871 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5781 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "248/248 [==============================] - 2s 10ms/step - loss: 0.5727 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 0.5675 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.5635 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5664 - accuracy: 0.9996\n",
            "Epoch 80/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.8626\n",
            "Epoch 81/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.6450 - accuracy: 0.9787\n",
            "Epoch 82/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5786 - accuracy: 0.9996\n",
            "Epoch 83/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5474 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.5431 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.5397 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.9999\n",
            "Epoch 89/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.7855 - accuracy: 0.9107\n",
            "Epoch 90/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.7031 - accuracy: 0.9437\n",
            "Epoch 91/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5716 - accuracy: 0.9968\n",
            "Epoch 92/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5418 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.5338 - accuracy: 0.9999\n",
            "Epoch 94/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5274 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5193 - accuracy: 0.9997\n",
            "Epoch 98/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5239 - accuracy: 0.9994\n",
            "Epoch 99/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.8659 - accuracy: 0.8723\n",
            "Epoch 100/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.6128 - accuracy: 0.9749\n",
            "Epoch 101/200\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 0.5345 - accuracy: 0.9992\n",
            "Epoch 102/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5179 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5113 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5039 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.5011 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4997 - accuracy: 0.9997\n",
            "Epoch 108/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5067 - accuracy: 0.9989\n",
            "Epoch 109/200\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 0.8922 - accuracy: 0.8515\n",
            "Epoch 110/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5817 - accuracy: 0.9809\n",
            "Epoch 111/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.9992\n",
            "Epoch 112/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5009 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4904 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4870 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4859 - accuracy: 0.9997\n",
            "Epoch 117/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.4836 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4917 - accuracy: 0.9984\n",
            "Epoch 119/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.9065 - accuracy: 0.8434\n",
            "Epoch 120/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5593 - accuracy: 0.9832\n",
            "Epoch 121/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5004 - accuracy: 0.9992\n",
            "Epoch 122/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4861 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4795 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4753 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 0.4721 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "248/248 [==============================] - 2s 10ms/step - loss: 0.4697 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4722 - accuracy: 0.9994\n",
            "Epoch 129/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.8365 - accuracy: 0.8601\n",
            "Epoch 130/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.5499 - accuracy: 0.9812\n",
            "Epoch 131/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.9999\n",
            "Epoch 132/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4710 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4655 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "248/248 [==============================] - 3s 12ms/step - loss: 0.4619 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4587 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4560 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4564 - accuracy: 0.9995\n",
            "Epoch 138/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.7816 - accuracy: 0.8827\n",
            "Epoch 139/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.5650 - accuracy: 0.9707\n",
            "Epoch 140/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4782 - accuracy: 0.9995\n",
            "Epoch 141/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.4608 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "248/248 [==============================] - 2s 10ms/step - loss: 0.4548 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4511 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4451 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4436 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4492 - accuracy: 0.9995\n",
            "Epoch 148/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.8189 - accuracy: 0.8677\n",
            "Epoch 149/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.5337 - accuracy: 0.9801\n",
            "Epoch 150/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4624 - accuracy: 0.9994\n",
            "Epoch 151/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4484 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4427 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4391 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4356 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4340 - accuracy: 0.9999\n",
            "Epoch 156/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4321 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "248/248 [==============================] - 3s 10ms/step - loss: 0.4328 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.6828 - accuracy: 0.9149\n",
            "Epoch 159/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.6407 - accuracy: 0.9297\n",
            "Epoch 160/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.9951\n",
            "Epoch 161/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4415 - accuracy: 0.9999\n",
            "Epoch 162/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4338 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4298 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4267 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4237 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "248/248 [==============================] - 3s 10ms/step - loss: 0.4219 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4220 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.7283 - accuracy: 0.8843\n",
            "Epoch 169/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.9696\n",
            "Epoch 170/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4469 - accuracy: 0.9990\n",
            "Epoch 171/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4290 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "248/248 [==============================] - 2s 10ms/step - loss: 0.4193 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.4164 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4143 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4770 - accuracy: 0.9774\n",
            "Epoch 178/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.7673 - accuracy: 0.8736\n",
            "Epoch 179/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4659 - accuracy: 0.9923\n",
            "Epoch 180/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4265 - accuracy: 0.9999\n",
            "Epoch 181/200\n",
            "248/248 [==============================] - 3s 10ms/step - loss: 0.4181 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.4135 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "248/248 [==============================] - 2s 7ms/step - loss: 0.4055 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4041 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4261 - accuracy: 0.9941\n",
            "Epoch 188/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.7894 - accuracy: 0.8604\n",
            "Epoch 189/200\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 0.4710 - accuracy: 0.9900\n",
            "Epoch 190/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4242 - accuracy: 0.9991\n",
            "Epoch 191/200\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 0.4062 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4028 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.4004 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.3989 - accuracy: 0.9999\n",
            "Epoch 196/200\n",
            "248/248 [==============================] - 1s 6ms/step - loss: 0.3973 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "248/248 [==============================] - 3s 12ms/step - loss: 0.3980 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "248/248 [==============================] - 2s 9ms/step - loss: 0.7501 - accuracy: 0.8770\n",
            "Epoch 199/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.5212 - accuracy: 0.9665\n",
            "Epoch 200/200\n",
            "248/248 [==============================] - 2s 8ms/step - loss: 0.4223 - accuracy: 0.9989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piqcKAMRbXiF",
        "outputId": "3a9681a5-f16f-4702-ae74-6fe79205f9ab"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 0s 2ms/step - loss: 3.0845 - accuracy: 0.4409\n",
            "Test Loss: 3.0844857692718506\n",
            "Test Accuracy: 0.44094255566596985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the test results from the above Neural Net\n",
        "\n",
        "# Get predicted probabilities for each class\n",
        "y_pred_probabilities = nn.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to predicted classes by selecting the class with the highest probability\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test_encoded back to categorical labels\n",
        "y_test_categorical = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Create a DataFrame to compare predicted and actual classes\n",
        "result_df = pd.DataFrame({'Actual': y_test_categorical, 'Predicted': y_pred})\n",
        "\n",
        "# Add a column indicating whether the prediction was correct\n",
        "result_df['Correct'] = result_df['Actual'] == result_df['Predicted']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n",
        "\n",
        "# Calculate accuracy manually\n",
        "accuracy = result_df['Correct'].mean()\n",
        "print(\"Manual Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7li0Nqy8hiM-",
        "outputId": "19d40fc5-112d-4407-c73c-98c44ac59530"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 5ms/step\n",
            "      Actual  Predicted  Correct\n",
            "0          9          0    False\n",
            "1          0          0     True\n",
            "2          0          8    False\n",
            "3          8          6    False\n",
            "4          8          7    False\n",
            "...      ...        ...      ...\n",
            "3390       9          2    False\n",
            "3391       4          4     True\n",
            "3392       4          4     True\n",
            "3393       0          8    False\n",
            "3394       1          2    False\n",
            "\n",
            "[3395 rows x 3 columns]\n",
            "Manual Test Accuracy: 0.4409425625920471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Export result_df to a CSV file\n",
        "result_df.to_csv('prediction_results.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('prediction_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dQRPGvqKhiUJ",
        "outputId": "2522bd2a-30a3-49d7-8366-abb9dae39aea"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0061db48-81a3-4007-ba3b-79aea88335dd\", \"prediction_results.csv\", 32478)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets add DrugName to the mix and see what we get"
      ],
      "metadata": {
        "id": "mWxuK8sqlhRu"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "embedded_df = pd.read_csv('embedded_review.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify it was loaded correctly\n",
        "embedded_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "zQ7e-jv5Ey-v",
        "outputId": "3a7666b2-5214-43ec-cda0-3e18863ec2e2"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   uniqueID                 drugName                     condition  \\\n",
              "0     95260               Guanfacine                          ADHD   \n",
              "1     92703                   Lybrel                 Birth Control   \n",
              "2    138000               Ortho Evra                 Birth Control   \n",
              "3     35696  Buprenorphine  naloxone             Opiate Dependence   \n",
              "4    155963                   Cialis  Benign Prostatic Hyperplasia   \n",
              "\n",
              "                                              review  rating       date  \\\n",
              "0  My son is halfway through his fourth week of I...     8.0  27-Apr-10   \n",
              "1  I used to take another oral contraceptive whic...     5.0  14-Dec-09   \n",
              "2  This is my first time using any form of birth ...     8.0   3-Nov-15   \n",
              "3  Suboxone has completely turned my life around ...     9.0  27-Nov-16   \n",
              "4  2nd day on 5mg started to work with rock hard ...     2.0  28-Nov-15   \n",
              "\n",
              "   usefulCount  lengthReview  conditionCluster_label  drugNameCluster_label  \\\n",
              "0        192.0         712.0                     2.0                    4.0   \n",
              "1         17.0         708.0                     9.0                    6.0   \n",
              "2         10.0         428.0                     9.0                    4.0   \n",
              "3         37.0         669.0                     0.0                    2.0   \n",
              "4         43.0         373.0                     0.0                    5.0   \n",
              "\n",
              "   ...       758       759       760       761       762       763       764  \\\n",
              "0  ... -0.416409 -0.364040 -0.036060  0.383963  0.176255 -0.147201 -0.243359   \n",
              "1  ... -0.279307 -0.419729 -0.389261  0.328398  0.291834 -0.027217 -0.359790   \n",
              "2  ... -0.232733 -0.031823 -0.032784  0.188440  0.162272  0.363399 -0.096650   \n",
              "3  ... -0.310564 -0.599643 -0.375174  0.309915  0.577983  0.051811 -0.184821   \n",
              "4  ... -0.247983 -0.438636 -0.037911 -0.030183  0.508780  0.064493 -0.205261   \n",
              "\n",
              "        765       766       767  \n",
              "0 -0.541467  0.062160  0.049585  \n",
              "1 -0.706709  0.047264 -0.017902  \n",
              "2 -0.693634 -0.024901  0.548486  \n",
              "3 -0.710691  0.065533  0.371945  \n",
              "4 -0.527391 -0.101341  0.039573  \n",
              "\n",
              "[5 rows x 778 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf045664-1e0d-455c-a8f3-3db76680137a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniqueID</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>lengthReview</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>drugNameCluster_label</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95260</td>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>My son is halfway through his fourth week of I...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>27-Apr-10</td>\n",
              "      <td>192.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.416409</td>\n",
              "      <td>-0.364040</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.383963</td>\n",
              "      <td>0.176255</td>\n",
              "      <td>-0.147201</td>\n",
              "      <td>-0.243359</td>\n",
              "      <td>-0.541467</td>\n",
              "      <td>0.062160</td>\n",
              "      <td>0.049585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92703</td>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>I used to take another oral contraceptive whic...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14-Dec-09</td>\n",
              "      <td>17.0</td>\n",
              "      <td>708.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.279307</td>\n",
              "      <td>-0.419729</td>\n",
              "      <td>-0.389261</td>\n",
              "      <td>0.328398</td>\n",
              "      <td>0.291834</td>\n",
              "      <td>-0.027217</td>\n",
              "      <td>-0.359790</td>\n",
              "      <td>-0.706709</td>\n",
              "      <td>0.047264</td>\n",
              "      <td>-0.017902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>138000</td>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>This is my first time using any form of birth ...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3-Nov-15</td>\n",
              "      <td>10.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232733</td>\n",
              "      <td>-0.031823</td>\n",
              "      <td>-0.032784</td>\n",
              "      <td>0.188440</td>\n",
              "      <td>0.162272</td>\n",
              "      <td>0.363399</td>\n",
              "      <td>-0.096650</td>\n",
              "      <td>-0.693634</td>\n",
              "      <td>-0.024901</td>\n",
              "      <td>0.548486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35696</td>\n",
              "      <td>Buprenorphine  naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>Suboxone has completely turned my life around ...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>27-Nov-16</td>\n",
              "      <td>37.0</td>\n",
              "      <td>669.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>-0.599643</td>\n",
              "      <td>-0.375174</td>\n",
              "      <td>0.309915</td>\n",
              "      <td>0.577983</td>\n",
              "      <td>0.051811</td>\n",
              "      <td>-0.184821</td>\n",
              "      <td>-0.710691</td>\n",
              "      <td>0.065533</td>\n",
              "      <td>0.371945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155963</td>\n",
              "      <td>Cialis</td>\n",
              "      <td>Benign Prostatic Hyperplasia</td>\n",
              "      <td>2nd day on 5mg started to work with rock hard ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28-Nov-15</td>\n",
              "      <td>43.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.247983</td>\n",
              "      <td>-0.438636</td>\n",
              "      <td>-0.037911</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>0.508780</td>\n",
              "      <td>0.064493</td>\n",
              "      <td>-0.205261</td>\n",
              "      <td>-0.527391</td>\n",
              "      <td>-0.101341</td>\n",
              "      <td>0.039573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 778 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf045664-1e0d-455c-a8f3-3db76680137a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf045664-1e0d-455c-a8f3-3db76680137a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf045664-1e0d-455c-a8f3-3db76680137a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43275ac6-e955-4646-b720-9808aff6905e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43275ac6-e955-4646-b720-9808aff6905e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43275ac6-e955-4646-b720-9808aff6905e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I am going to drop the columns that are not embeddings of the review and the condition_cluster\n",
        "\n",
        "columns_to_drop = ['uniqueID', 'drugNameCluster_label', 'date', 'condition', 'review', 'lengthReview']\n",
        "\n",
        "embedded_df.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "rmX-93lrE3EZ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "fDGXF0RtFLGO",
        "outputId": "93802db9-c589-444b-fcf0-02f290eda737"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  drugName  rating  usefulCount  conditionCluster_label  \\\n",
              "0               Guanfacine     8.0        192.0                     2.0   \n",
              "1                   Lybrel     5.0         17.0                     9.0   \n",
              "2               Ortho Evra     8.0         10.0                     9.0   \n",
              "3  Buprenorphine  naloxone     9.0         37.0                     0.0   \n",
              "4                   Cialis     2.0         43.0                     0.0   \n",
              "\n",
              "          0         1         2         3         4         5  ...       758  \\\n",
              "0 -0.010977  0.010914  0.200967 -0.229490 -0.535286  0.012419  ... -0.416409   \n",
              "1  0.066320  0.189584  0.369006 -0.046920 -0.473988 -0.238288  ... -0.279307   \n",
              "2  0.084101 -0.019134  0.294494  0.029783 -0.228783  0.170102  ... -0.232733   \n",
              "3  0.007820  0.207558  0.179105 -0.210057 -0.197015  0.104799  ... -0.310564   \n",
              "4 -0.193177  0.360585  0.448292 -0.253824 -0.532782  0.085381  ... -0.247983   \n",
              "\n",
              "        759       760       761       762       763       764       765  \\\n",
              "0 -0.364040 -0.036060  0.383963  0.176255 -0.147201 -0.243359 -0.541467   \n",
              "1 -0.419729 -0.389261  0.328398  0.291834 -0.027217 -0.359790 -0.706709   \n",
              "2 -0.031823 -0.032784  0.188440  0.162272  0.363399 -0.096650 -0.693634   \n",
              "3 -0.599643 -0.375174  0.309915  0.577983  0.051811 -0.184821 -0.710691   \n",
              "4 -0.438636 -0.037911 -0.030183  0.508780  0.064493 -0.205261 -0.527391   \n",
              "\n",
              "        766       767  \n",
              "0  0.062160  0.049585  \n",
              "1  0.047264 -0.017902  \n",
              "2 -0.024901  0.548486  \n",
              "3  0.065533  0.371945  \n",
              "4 -0.101341  0.039573  \n",
              "\n",
              "[5 rows x 772 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09a423f1-1e99-47ea-8097-25fe243cadbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>rating</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>8.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.010977</td>\n",
              "      <td>0.010914</td>\n",
              "      <td>0.200967</td>\n",
              "      <td>-0.229490</td>\n",
              "      <td>-0.535286</td>\n",
              "      <td>0.012419</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.416409</td>\n",
              "      <td>-0.364040</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.383963</td>\n",
              "      <td>0.176255</td>\n",
              "      <td>-0.147201</td>\n",
              "      <td>-0.243359</td>\n",
              "      <td>-0.541467</td>\n",
              "      <td>0.062160</td>\n",
              "      <td>0.049585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lybrel</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.066320</td>\n",
              "      <td>0.189584</td>\n",
              "      <td>0.369006</td>\n",
              "      <td>-0.046920</td>\n",
              "      <td>-0.473988</td>\n",
              "      <td>-0.238288</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.279307</td>\n",
              "      <td>-0.419729</td>\n",
              "      <td>-0.389261</td>\n",
              "      <td>0.328398</td>\n",
              "      <td>0.291834</td>\n",
              "      <td>-0.027217</td>\n",
              "      <td>-0.359790</td>\n",
              "      <td>-0.706709</td>\n",
              "      <td>0.047264</td>\n",
              "      <td>-0.017902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.084101</td>\n",
              "      <td>-0.019134</td>\n",
              "      <td>0.294494</td>\n",
              "      <td>0.029783</td>\n",
              "      <td>-0.228783</td>\n",
              "      <td>0.170102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232733</td>\n",
              "      <td>-0.031823</td>\n",
              "      <td>-0.032784</td>\n",
              "      <td>0.188440</td>\n",
              "      <td>0.162272</td>\n",
              "      <td>0.363399</td>\n",
              "      <td>-0.096650</td>\n",
              "      <td>-0.693634</td>\n",
              "      <td>-0.024901</td>\n",
              "      <td>0.548486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Buprenorphine  naloxone</td>\n",
              "      <td>9.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.207558</td>\n",
              "      <td>0.179105</td>\n",
              "      <td>-0.210057</td>\n",
              "      <td>-0.197015</td>\n",
              "      <td>0.104799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>-0.599643</td>\n",
              "      <td>-0.375174</td>\n",
              "      <td>0.309915</td>\n",
              "      <td>0.577983</td>\n",
              "      <td>0.051811</td>\n",
              "      <td>-0.184821</td>\n",
              "      <td>-0.710691</td>\n",
              "      <td>0.065533</td>\n",
              "      <td>0.371945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cialis</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.193177</td>\n",
              "      <td>0.360585</td>\n",
              "      <td>0.448292</td>\n",
              "      <td>-0.253824</td>\n",
              "      <td>-0.532782</td>\n",
              "      <td>0.085381</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.247983</td>\n",
              "      <td>-0.438636</td>\n",
              "      <td>-0.037911</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>0.508780</td>\n",
              "      <td>0.064493</td>\n",
              "      <td>-0.205261</td>\n",
              "      <td>-0.527391</td>\n",
              "      <td>-0.101341</td>\n",
              "      <td>0.039573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 772 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09a423f1-1e99-47ea-8097-25fe243cadbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09a423f1-1e99-47ea-8097-25fe243cadbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09a423f1-1e99-47ea-8097-25fe243cadbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3f51f09-469c-4d40-96f9-b7eca8fc0a96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3f51f09-469c-4d40-96f9-b7eca8fc0a96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3f51f09-469c-4d40-96f9-b7eca8fc0a96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert drugname into multiple columns of dummy variables\n",
        "\n",
        "dummies_drugs = pd.get_dummies(embedded_df['drugName'])\n",
        "\n",
        "# Concatenate dummy variables with the original DataFrame\n",
        "embedded_df = pd.concat([\n",
        "    embedded_df.drop(columns=['drugName']),\n",
        "    dummies_drugs\n",
        "], axis=1)"
      ],
      "metadata": {
        "id": "r03wJnz9FW6y"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "1xxW3BgQHHQ4",
        "outputId": "0bdefe0e-2af4-49d1-96ee-1780e62006e9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  usefulCount  conditionCluster_label         0         1         2  \\\n",
              "0     8.0        192.0                     2.0 -0.010977  0.010914  0.200967   \n",
              "1     5.0         17.0                     9.0  0.066320  0.189584  0.369006   \n",
              "2     8.0         10.0                     9.0  0.084101 -0.019134  0.294494   \n",
              "3     9.0         37.0                     0.0  0.007820  0.207558  0.179105   \n",
              "4     2.0         43.0                     0.0 -0.193177  0.360585  0.448292   \n",
              "\n",
              "          3         4         5         6  ...  Zovirax Ointment  Zyban  \\\n",
              "0 -0.229490 -0.535286  0.012419  0.578620  ...                 0      0   \n",
              "1 -0.046920 -0.473988 -0.238288  0.341089  ...                 0      0   \n",
              "2  0.029783 -0.228783  0.170102  0.185404  ...                 0      0   \n",
              "3 -0.210057 -0.197015  0.104799  0.338058  ...                 0      0   \n",
              "4 -0.253824 -0.532782  0.085381  0.607802  ...                 0      0   \n",
              "\n",
              "   Zyclara  Zymine  Zyprexa  Zyprexa Zydis  Zyrtec  Zyvox  ella  femhrt  \n",
              "0        0       0        0              0       0      0     0       0  \n",
              "1        0       0        0              0       0      0     0       0  \n",
              "2        0       0        0              0       0      0     0       0  \n",
              "3        0       0        0              0       0      0     0       0  \n",
              "4        0       0        0              0       0      0     0       0  \n",
              "\n",
              "[5 rows x 2193 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b9e4031-2782-42e3-b147-878c46368786\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>...</th>\n",
              "      <th>Zovirax Ointment</th>\n",
              "      <th>Zyban</th>\n",
              "      <th>Zyclara</th>\n",
              "      <th>Zymine</th>\n",
              "      <th>Zyprexa</th>\n",
              "      <th>Zyprexa Zydis</th>\n",
              "      <th>Zyrtec</th>\n",
              "      <th>Zyvox</th>\n",
              "      <th>ella</th>\n",
              "      <th>femhrt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.010977</td>\n",
              "      <td>0.010914</td>\n",
              "      <td>0.200967</td>\n",
              "      <td>-0.229490</td>\n",
              "      <td>-0.535286</td>\n",
              "      <td>0.012419</td>\n",
              "      <td>0.578620</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.066320</td>\n",
              "      <td>0.189584</td>\n",
              "      <td>0.369006</td>\n",
              "      <td>-0.046920</td>\n",
              "      <td>-0.473988</td>\n",
              "      <td>-0.238288</td>\n",
              "      <td>0.341089</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.084101</td>\n",
              "      <td>-0.019134</td>\n",
              "      <td>0.294494</td>\n",
              "      <td>0.029783</td>\n",
              "      <td>-0.228783</td>\n",
              "      <td>0.170102</td>\n",
              "      <td>0.185404</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.207558</td>\n",
              "      <td>0.179105</td>\n",
              "      <td>-0.210057</td>\n",
              "      <td>-0.197015</td>\n",
              "      <td>0.104799</td>\n",
              "      <td>0.338058</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.193177</td>\n",
              "      <td>0.360585</td>\n",
              "      <td>0.448292</td>\n",
              "      <td>-0.253824</td>\n",
              "      <td>-0.532782</td>\n",
              "      <td>0.085381</td>\n",
              "      <td>0.607802</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2193 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b9e4031-2782-42e3-b147-878c46368786')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b9e4031-2782-42e3-b147-878c46368786 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b9e4031-2782-42e3-b147-878c46368786');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab307618-7d74-4d31-aa40-c2e7aa20c273\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab307618-7d74-4d31-aa40-c2e7aa20c273')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab307618-7d74-4d31-aa40-c2e7aa20c273 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When I start training the model I am getting an error messsage that NAN values are present\n",
        "embedded_df = embedded_df.dropna(subset=['conditionCluster_label'])"
      ],
      "metadata": {
        "id": "QXv55kztHMtC"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "da6ptecbF4ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data split step\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Separate the target variable\n",
        "target = embedded_df['conditionCluster_label']\n",
        "\n",
        "# Verify the unique values in the target variable\n",
        "print(target.unique())\n",
        "\n",
        "# Extract features (excluding the target variable)\n",
        "features = embedded_df.drop(columns=['conditionCluster_label'])\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=30)\n",
        "\n",
        "# Convert target labels to one-hot encoded format\n",
        "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Check the shapes of the one-hot encoded target labels\n",
        "print(\"Shape of y_train_encoded:\", y_train_encoded.shape)\n",
        "print(\"Shape of y_test_encoded:\", y_test_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH7UwEr4FRsN",
        "outputId": "82823511-f80d-4a67-d660-e30115b82133"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 9. 0. 1. 3. 8. 5. 7. 4. 6.]\n",
            "Shape of y_train_encoded: (7920, 10)\n",
            "Shape of y_test_encoded: (3395, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Cbk2YUELHK3v"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dimensions, make it a variable so it passes into\n",
        "\n",
        "num_dimensions = embedded_df.shape[1]-1\n",
        "print(num_dimensions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQQAzdb7HXFR",
        "outputId": "fc50cc7e-6c99-4b0d-e658-c2cbe98e6d6c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "# Most of this is going to be the same as the HW assignment, but there are 10 classifications to predict now\n",
        "# So the output layer has been adjusted\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=num_dimensions, activation=\"relu\", input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(Dense(units=600, activation='leaky_relu'))\n",
        "\n",
        "# Third hidden layer (example of adding an additional hidden layer)\n",
        "nn.add(Dense(units=300, activation='relu'))\n",
        "\n",
        "#Fourth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=150, activation='ELU'))\n",
        "\n",
        "#Fifth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=100, activation='leaky_relu'))\n",
        "\n",
        "#Sixth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=50, activation='relu'))\n",
        "\n",
        "#Seventh hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=25, activation='ELU'))\n",
        "\n",
        "#Eighth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=15, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=10, activation='softmax'))  # 10 units for 10 classes, softmax activation\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeJksc2RHd7d",
        "outputId": "dcc444d7-9873-422b-8bd4-f8678d509f49"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 2192)              4807056   \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 600)               1315800   \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 300)               180300    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 150)               45150     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 100)               15100     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 15)                390       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6370281 (24.30 MB)\n",
            "Trainable params: 6370281 (24.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model - the loss function is categorical and not for binary classification\n",
        "\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "sQ1twvNvHpnY"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjYyd4lmHtld",
        "outputId": "5eb8b5f2-f935-47f3-a74c-8fa001e2a4c8"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "248/248 [==============================] - 26s 96ms/step - loss: 1.5603 - accuracy: 0.4581\n",
            "Epoch 2/10\n",
            "248/248 [==============================] - 25s 99ms/step - loss: 0.8334 - accuracy: 0.7179\n",
            "Epoch 3/10\n",
            "248/248 [==============================] - 23s 91ms/step - loss: 0.5918 - accuracy: 0.7958\n",
            "Epoch 4/10\n",
            "248/248 [==============================] - 24s 99ms/step - loss: 0.4643 - accuracy: 0.8407\n",
            "Epoch 5/10\n",
            "248/248 [==============================] - 25s 100ms/step - loss: 0.3864 - accuracy: 0.8650\n",
            "Epoch 6/10\n",
            "248/248 [==============================] - 24s 95ms/step - loss: 0.3002 - accuracy: 0.8996\n",
            "Epoch 7/10\n",
            "248/248 [==============================] - 23s 91ms/step - loss: 0.2565 - accuracy: 0.9097\n",
            "Epoch 8/10\n",
            "248/248 [==============================] - 23s 93ms/step - loss: 0.2405 - accuracy: 0.9249\n",
            "Epoch 9/10\n",
            "248/248 [==============================] - 28s 113ms/step - loss: 0.1727 - accuracy: 0.9453\n",
            "Epoch 10/10\n",
            "248/248 [==============================] - 22s 91ms/step - loss: 0.1568 - accuracy: 0.9514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr3Q9KcqItuW",
        "outputId": "25ba3152-5b2d-42b1-d978-af69203f1df4"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 2s 16ms/step - loss: 1.3861 - accuracy: 0.7093\n",
            "Test Loss: 1.3861266374588013\n",
            "Test Accuracy: 0.7092783451080322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the test results from the above Neural Net\n",
        "\n",
        "# Get predicted probabilities for each class\n",
        "y_pred_probabilities = nn.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to predicted classes by selecting the class with the highest probability\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test_encoded back to categorical labels\n",
        "y_test_categorical = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Create a DataFrame to compare predicted and actual classes\n",
        "result_df = pd.DataFrame({'Actual': y_test_categorical, 'Predicted': y_pred})\n",
        "\n",
        "# Add a column indicating whether the prediction was correct\n",
        "result_df['Correct'] = result_df['Actual'] == result_df['Predicted']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n",
        "\n",
        "# Calculate accuracy manually\n",
        "accuracy = result_df['Correct'].mean()\n",
        "print(\"Manual Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfaz2BzJkkWm",
        "outputId": "72815e3a-a397-404d-e62a-7bec0b98398b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 4s 38ms/step\n",
            "      Actual  Predicted  Correct\n",
            "0          9          9     True\n",
            "1          0          0     True\n",
            "2          0          0     True\n",
            "3          8          4    False\n",
            "4          8          0    False\n",
            "...      ...        ...      ...\n",
            "3390       9          9     True\n",
            "3391       4          1    False\n",
            "3392       4          4     True\n",
            "3393       0          8    False\n",
            "3394       1          4    False\n",
            "\n",
            "[3395 rows x 3 columns]\n",
            "Manual Test Accuracy: 0.709278350515464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9NaEKGwkkaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# Define the model-building function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(units=hp.Int('units_input', min_value=64, max_value=800, step=64), activation='relu', input_dim=num_dimensions))\n",
        "    for i in range(hp.Int('num_layers', 1, 8)):  # Number of hidden layers\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=64, max_value=512, step=64), activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Instantiate the tuner and perform hyperparameter search\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='helloworld')\n",
        "\n",
        "tuner.search(X_train_scaled, y_train_encoded, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Optimal number of units in the input layer: {best_hps.get('units_input')}\")\n",
        "print(f\"Optimal learning rate for the optimizer: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Optimal number of hidden layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Optimal number of units in layer {i}: {best_hps.get('units_' + str(i))}\")\n",
        "\n",
        "# Build the model with the best hyperparameters and train it on the data\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_scaled, y_train_encoded, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "it8ei8VJHwup",
        "outputId": "2d3ba5c6-04d6-47f2-b019-d535998670f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_dir/helloworld/tuner0.json\n",
            "\n",
            "Search: Running Trial #2\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "576               |192               |units_input\n",
            "6                 |5                 |num_layers\n",
            "192               |256               |units_0\n",
            "0.001             |0.0001            |learning_rate\n",
            "384               |64                |units_1\n",
            "128               |64                |units_2\n",
            "192               |64                |units_3\n",
            "384               |64                |units_4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7fb69d02c040>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "198/198 [==============================] - 6s 23ms/step - loss: 1.5118 - accuracy: 0.4508 - val_loss: 1.0989 - val_accuracy: 0.5903\n",
            "Epoch 2/5\n",
            "198/198 [==============================] - 6s 29ms/step - loss: 0.7239 - accuracy: 0.7334 - val_loss: 0.8871 - val_accuracy: 0.6963\n",
            "Epoch 3/5\n",
            "198/198 [==============================] - 4s 22ms/step - loss: 0.4490 - accuracy: 0.8406 - val_loss: 0.9307 - val_accuracy: 0.7058\n",
            "Epoch 4/5\n",
            "198/198 [==============================] - 5s 24ms/step - loss: 0.3406 - accuracy: 0.8755 - val_loss: 1.0384 - val_accuracy: 0.7165\n",
            "Epoch 5/5\n",
            "198/198 [==============================] - 5s 27ms/step - loss: 0.2573 - accuracy: 0.9132 - val_loss: 1.0797 - val_accuracy: 0.7045\n",
            "Epoch 1/5\n",
            "198/198 [==============================] - 7s 29ms/step - loss: 1.5103 - accuracy: 0.4680 - val_loss: 1.1325 - val_accuracy: 0.5922\n",
            "Epoch 2/5\n",
            "198/198 [==============================] - 4s 22ms/step - loss: 0.7407 - accuracy: 0.7320 - val_loss: 0.8725 - val_accuracy: 0.6963\n",
            "Epoch 3/5\n",
            "198/198 [==============================] - 4s 22ms/step - loss: 0.4857 - accuracy: 0.8223 - val_loss: 0.9130 - val_accuracy: 0.7058\n",
            "Epoch 4/5\n",
            "198/198 [==============================] - 6s 29ms/step - loss: 0.3531 - accuracy: 0.8726 - val_loss: 0.9293 - val_accuracy: 0.7121\n",
            "Epoch 5/5\n",
            "198/198 [==============================] - 5s 23ms/step - loss: 0.2769 - accuracy: 0.9056 - val_loss: 1.0214 - val_accuracy: 0.7121\n",
            "Epoch 1/5\n",
            "198/198 [==============================] - 7s 24ms/step - loss: 1.5745 - accuracy: 0.4511 - val_loss: 1.0851 - val_accuracy: 0.5783\n",
            "Epoch 2/5\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 0.7939 - accuracy: 0.7199 - val_loss: 0.9334 - val_accuracy: 0.6869\n",
            "Epoch 3/5\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 0.5082 - accuracy: 0.8213 - val_loss: 0.8838 - val_accuracy: 0.7109\n",
            "Epoch 4/5\n",
            "198/198 [==============================] - 4s 20ms/step - loss: 0.3693 - accuracy: 0.8717 - val_loss: 1.0139 - val_accuracy: 0.7052\n",
            "Epoch 5/5\n",
            "198/198 [==============================] - 4s 23ms/step - loss: 0.2916 - accuracy: 0.8987 - val_loss: 1.1139 - val_accuracy: 0.7197\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-64af5deb9134>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     project_name='helloworld')\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Get the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusting the learning rate\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the model - deep neural net with L2 regularization\n",
        "nn = Sequential()\n",
        "\n",
        "# First hidden layer with L2 regularization\n",
        "nn.add(Dense(units=771, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer with L2 regularization\n",
        "nn.add(Dense(units=512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Third hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Fourth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Fifth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Sixth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Seventh hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Eighth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Define optimizer with custom learning rate\n",
        "custom_optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compile the model with the custom optimizer\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=custom_optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "fPwbgloZInXZ",
        "outputId": "40ce5ce2-9a30-4625-9b0d-a5d4057beb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "220/248 [=========================>....] - ETA: 1s - loss: 6.0349 - accuracy: 0.3598"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-489897fd28a1>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit the model to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2vZ9zxONBAq",
        "outputId": "8668fd4d-9ba0-4215-bda6-abd141f1d853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 8ms/step - loss: 2.3216 - accuracy: 0.3602\n",
            "Test Loss: 2.3216376304626465\n",
            "Test Accuracy: 0.36023563146591187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get predicted probabilities for each class\n",
        "y_pred_probabilities = nn.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to predicted classes by selecting the class with the highest probability\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test_encoded back to categorical labels\n",
        "y_test_categorical = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Create a DataFrame to compare predicted and actual classes\n",
        "result_df = pd.DataFrame({'Actual': y_test_categorical, 'Predicted': y_pred})\n",
        "\n",
        "# Add a column indicating whether the prediction was correct\n",
        "result_df['Correct'] = result_df['Actual'] == result_df['Predicted']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n",
        "\n",
        "# Calculate accuracy manually\n",
        "accuracy = result_df['Correct'].mean()\n",
        "print(\"Manual Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "S-_S2U8jXoXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3aa4065-3721-4250-a168-7bcbeb177544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 12ms/step\n",
            "      Actual  Predicted  Correct\n",
            "0          9          0    False\n",
            "1          0          0     True\n",
            "2          0          0     True\n",
            "3          8          0    False\n",
            "4          8          0    False\n",
            "...      ...        ...      ...\n",
            "3390       9          0    False\n",
            "3391       4          0    False\n",
            "3392       4          0    False\n",
            "3393       0          0     True\n",
            "3394       1          0    False\n",
            "\n",
            "[3395 rows x 3 columns]\n",
            "Manual Test Accuracy: 0.3602356406480118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Export result_df to a CSV file\n",
        "result_df.to_csv('prediction_results.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('prediction_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q8T54cn-LQKU",
        "outputId": "b43de75e-cbde-43fa-c99a-e4b0cd8f219f"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_399dc43e-27df-427f-b1e6-c753667731f6\", \"prediction_results.csv\", 31567)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQCv5ZlPLoKr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}